{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re, operator\n",
    "from pprint import pprint\n",
    "\n",
    "from src.utils import *\n",
    "from src.k_nearest_neighbors import *\n",
    "from src.logistic_regression import *\n",
    "from src.naive_bayes import *\n",
    "from src.neutral_network import *\n",
    "#from src.support_vector_machines import *\n",
    "from src.validation import *\n",
    "\n",
    "PATH_POSITIVE_TRUTHFUL  = 'op_spam_v1.4/positive/truthful/'\n",
    "PATH_POSITIVE_DECEPTIVE = 'op_spam_v1.4/positive/deceptive/'\n",
    "PATH_NEGATIVE_TRUTHFUL  = 'op_spam_v1.4/negative/truthful/'\n",
    "PATH_NEGATIVE_DECEPTIVE = 'op_spam_v1.4/negative/deceptive/'\n",
    "ALL_PATH = [PATH_POSITIVE_TRUTHFUL, PATH_POSITIVE_DECEPTIVE,\n",
    "           PATH_NEGATIVE_TRUTHFUL, PATH_NEGATIVE_DECEPTIVE]\n",
    "\n",
    "def wordsProcessed(paths, threshold):\n",
    "    dic = {}\n",
    "    dic2 = {}\n",
    "    dirs =[]\n",
    "    \n",
    "    for p in paths:\n",
    "        silence = [p+t for t in os.listdir(p)]\n",
    "        dirs += (silence)\n",
    "    \n",
    "    for texts in dirs:\n",
    "        with open(texts, 'r', encoding='utf-8') as stream:\n",
    "            text = stream.read()\n",
    "            wordSplited = []\n",
    "            \n",
    "            #Pre-pre processing\n",
    "            wordSplited2 = [word for word in (re.sub(r'[^\\w\\s]+','', text.replace('\\n','')).lower().split(' ')) if word != '']\n",
    "\n",
    "            #N-Gram\n",
    "            for index in range(2, 5):\n",
    "                ngrams = zip(*[wordSplited2[i:] for i in range(index)])\n",
    "                wordSplited += ([\" \".join(ngram) for ngram in ngrams])\n",
    "            \n",
    "            #Creating dictonary for count n-gram words\n",
    "            for word in wordSplited:\n",
    "                if word in dic:\n",
    "                    dic[word] += 1\n",
    "                else:\n",
    "                    dic[word] = 1\n",
    "                    \n",
    "    #Remove values < threshold\n",
    "    for key, value in dic.items():\n",
    "        if value > threshold:\n",
    "            dic2[key] = value\n",
    "    listWords = [k for k, v in dic2.items()]\n",
    "    dic2 = sorted(dic2.items(), key=operator.itemgetter(1))\n",
    "    \n",
    "    return wordSplited, dic2, listWords\n",
    "\n",
    "# posTruthWordSplited, posTruthDic, listWords = wordsProcessed([PATH_POSITIVE_DECEPTIVE, PATH_NEGATIVE_DECEPTIVE], 5)\n",
    "posTruthWordSplited, posTruthDic, listWords = wordsProcessed([PATH_POSITIVE_DECEPTIVE], 3)\n",
    "# posTruthWordSplited, posTruthDic, listWords = wordsProcessed([PATH_NEGATIVE_DECEPTIVE], 3)\n",
    "\n",
    "#pprint(posTruthDic)\n",
    "print(len(posTruthDic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "Y = []\n",
    "def generateFeatures(path, example_class):\n",
    "    i = 1\n",
    "    for texts in os.listdir(path):\n",
    "        i+=1\n",
    "        print(i)\n",
    "        aux = np.zeros(len(listWords) + 1)\n",
    "        with open(path + texts, 'r', encoding='utf-8') as stream:\n",
    "            #Pre-pre processing\n",
    "            text = stream.read()\n",
    "            allNgrams = []\n",
    "            wordSplited = [word for word in (re.sub(r'[^\\w\\s]+','', text.replace('\\n','')).lower().split(' ')) if word != '']\n",
    "\n",
    "            #N-Gram\n",
    "            for index in range(2, 5):\n",
    "                ngrams = zip(*[wordSplited[i:] for i in range(index)])\n",
    "                allNgrams += ([\" \".join(ngram) for ngram in ngrams])\n",
    "            \n",
    "            for idx, word in enumerate(listWords):\n",
    "                for ngram in allNgrams:\n",
    "                    if word == ngram:\n",
    "                        aux[idx] += 1\n",
    "\n",
    "            Y.append(example_class)\n",
    "            matrix.append(aux)\n",
    "            \n",
    "generateFeatures(PATH_POSITIVE_DECEPTIVE, 1)\n",
    "generateFeatures(PATH_POSITIVE_TRUTHFUL, 0)\n",
    "\n",
    "matrix = np.array(matrix)\n",
    "matrix_norm, mu, sigma = normalize(matrix)\n",
    "\n",
    "#save(np.column_stack((matrix_norm, matrix[:, -1])), listWords)\n",
    "print('ACABOOOOOOO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if matrix_norm.shape[1] != len(posTruthDic):\n",
    "    raise Exception('Tamanhos diferentes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = matrix_norm[400:720]\n",
    "b = matrix_norm[0:320]\n",
    "X2 = np.append(a,b, axis=0)\n",
    "\n",
    "a = Y[400:720]\n",
    "b = Y[0:320]\n",
    "Y2 = np.append(a,b, axis=0)\n",
    "\n",
    "a = matrix_norm[720:800]\n",
    "b = matrix_norm[320:400]\n",
    "X_val = np.append(a,b, axis=0)\n",
    "\n",
    "a = Y[720:800]\n",
    "b = Y[320:400]\n",
    "Y_val = np.append(a,b, axis=0)\n",
    "\n",
    "#custo, gamma = svm(X2, Y2, X_val, Y_val)\n",
    "#print(custo, '\\t', gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = knn(X_val[81], X2, Y2, 5)\n",
    "#print(Y_val[81], ' ',y,' ', ind_viz)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = stratified_kfolds(Y, 5, np.unique(Y))\n",
    "\n",
    "for train_index, test_index in folds:\n",
    "    print('Train: ',len(train_index))\n",
    "    print('Test: ',len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# resultados = []\n",
    "# for x in range(0, 5):\n",
    "#     Y_resultado = np.array([random.randint(0, 1) for i in range(0, 160)])\n",
    "#     Y_classes = np.array([random.randint(0, 1) for i in range(0, 160)])\n",
    "#     classes = [0, 1]\n",
    "\n",
    "#     cm = get_confusionMatrix(Y_classes, Y_resultado, classes)\n",
    "    \n",
    "    \n",
    "#     resultado = relatorioDesempenho(cm, classes, False)\n",
    "#     resultados.append(resultado)\n",
    "\n",
    "# mediaFolds(resultados, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES\n",
    "\n",
    "resultados = []\n",
    "classes = np.unique(Y)\n",
    "\n",
    "for train_index, test_index in folds:\n",
    "    # Treinamento\n",
    "    probsPos, probsNeg = calcularProbabilidades(matrix[:, :-1][train_index], Y[train_index])\n",
    "    \n",
    "    # Classificação\n",
    "    pred = []\n",
    "    for x in matrix[:, :-1][test_index]:\n",
    "        probPos, probNeg = classificacao(x, probsPos, probsNeg, sum(Y[train_index] == 1)/len(Y[train_index]), sum(Y[train_index] == 0)/len(Y[train_index]))\n",
    "        if (probPos >= probNeg):\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "\n",
    "    cm = get_confusionMatrix(Y[test_index], pred, np.unique(Y))\n",
    "    resultado = relatorioDesempenho(cm, classes, False)\n",
    "    \n",
    "    resultados.append(resultado)\n",
    "\n",
    "mediaFolds(resultados, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
